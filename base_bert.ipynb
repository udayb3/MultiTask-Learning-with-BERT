{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", torch_dtype=torch.float16, attn_implementation=\"sdpa\")\n",
    "tokenizer= BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text = \"Hello, how are you?\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Extract outputs\n",
    "sequence_output = outputs.last_hidden_state\n",
    "pooled_output = outputs.pooler_output\n",
    "\n",
    "print(\"Sequence Output Shape:\", sequence_output.shape)\n",
    "print(\"Pooled Output Shape:\", pooled_output.shape)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
