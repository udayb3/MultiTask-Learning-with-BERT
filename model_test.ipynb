{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "from transformers import BertTokenizer\n",
    "import csv, time, random, numpy as np, pandas as pd\n",
    "from types import SimpleNamespace\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    return ' '.join(s.lower().replace('.', ' .').replace('?', ' ?').replace(',', ' ,').replace('\\'', ' \\'').split())\n",
    "\n",
    "class SentenceClassificationDataset(Dataset):\n",
    "    \"\"\"Inheriting the dataset class for the sentence classification task\"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset; self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    def pad_data(self, data):\n",
    "        '''This function pads the data to the max length of the batch'''\n",
    "        sents = [x[0] for x in data]\n",
    "        labels = [int(x[1])-1 for x in data] # subtracting to accomodate for 0-indexed classes\n",
    "        sent_ids = [x[2] for x in data]\n",
    "\n",
    "        encoding = self.tokenizer(sents, return_tensors='pt', padding=True, truncation=True)\n",
    "        token_ids = torch.LongTensor(encoding['input_ids']);    attention_mask = torch.LongTensor(encoding['attention_mask']);  labels = torch.LongTensor(labels)\n",
    "\n",
    "        return token_ids, attention_mask, labels, sents, sent_ids\n",
    "\n",
    "    def collate_fn(self, all_data):\n",
    "        token_ids, attention_mask, labels, sents, sent_ids= self.pad_data(all_data)\n",
    "\n",
    "        batched_data = { 'token_ids': token_ids, 'attention_mask': attention_mask, 'labels': labels, 'sents': sents, 'sent_ids': sent_ids }\n",
    "        return batched_data\n",
    "\n",
    "class SentencePairDataset(Dataset):\n",
    "    def __init__(self, dataset, isRegression =False):\n",
    "        self.dataset = dataset\n",
    "        self.isRegression = isRegression\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    def pad_data(self, data):\n",
    "        sent1 = [x[0] for x in data]\n",
    "        sent2 = [x[1] for x in data]\n",
    "        labels = [x[2] for x in data]\n",
    "        sent_ids = [x[3] for x in data]\n",
    "\n",
    "        encoding1 = self.tokenizer(sent1, return_tensors='pt', padding=True, truncation=True)\n",
    "        encoding2 = self.tokenizer(sent2, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "        token_ids = torch.LongTensor(encoding1['input_ids'])\n",
    "        attention_mask = torch.LongTensor(encoding1['attention_mask'])\n",
    "        token_type_ids = torch.LongTensor(encoding1['token_type_ids'])\n",
    "\n",
    "        token_ids2 = torch.LongTensor(encoding2['input_ids'])\n",
    "        attention_mask2 = torch.LongTensor(encoding2['attention_mask'])\n",
    "        token_type_ids2 = torch.LongTensor(encoding2['token_type_ids'])\n",
    "        if self.isRegression:\n",
    "            labels = torch.FloatTensor(labels)\n",
    "        else:\n",
    "            labels = torch.LongTensor(labels)\n",
    "            \n",
    "\n",
    "        return (token_ids, token_type_ids, attention_mask,\n",
    "                token_ids2, token_type_ids2, attention_mask2,\n",
    "                labels,sent_ids)\n",
    "\n",
    "    def collate_fn(self, all_data):\n",
    "        (token_ids, token_type_ids, attention_mask, token_ids2, token_type_ids2, attention_mask2, labels, sent_ids) = self.pad_data(all_data)\n",
    "\n",
    "        batched_data = { 'token_ids_1': token_ids, 'token_type_ids_1': token_type_ids, 'attention_mask_1': attention_mask, 'token_ids_2': token_ids2, 'token_type_ids_2': token_type_ids2, 'attention_mask_2': attention_mask2, 'labels': labels, 'sent_ids': sent_ids }\n",
    "        return batched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_multitask_data( sentiment_filename, paraphrase_filename, similarity_filename, emotion_filename, split='train'):\n",
    "    '''This function loads the training datasets for the multitask dataset'''\n",
    "    sentiment_data = []\n",
    "    num_labels = {}\n",
    "\n",
    "    with open(sentiment_filename, 'r') as fp:\n",
    "        for record in csv.DictReader(fp,delimiter = '\\t'):\n",
    "            sent = record['sentence'].lower().strip()\n",
    "            sent_id = record['id'].lower().strip()\n",
    "            label = int(record['sentiment'].strip())\n",
    "            if label not in num_labels:\n",
    "                num_labels[label] = len(num_labels)\n",
    "            sentiment_data.append((sent, label,sent_id))\n",
    "\n",
    "    print(f\"Loaded {len(sentiment_data)} {split} examples from {sentiment_filename}\")\n",
    "\n",
    "    emotion_data= []\n",
    "    with open(emotion_filename, 'r') as fp:\n",
    "        for record in csv.DictReader(fp,delimiter = '\\t'):\n",
    "            sent = record['sentence'].lower().strip()\n",
    "            sent_id = record['id'].lower().strip()\n",
    "            label = int(record['sentiment'].strip())\n",
    "            if label not in num_labels:\n",
    "                num_labels[label] = len(num_labels)\n",
    "            emotion_data.append((sent, label,sent_id))\n",
    "\n",
    "    print(f\"Loaded {len(emotion_data)} {split} examples from {emotion_filename}\")\n",
    "\n",
    "    paraphrase_data = []\n",
    "    with open(paraphrase_filename, 'r') as fp:\n",
    "        for record in csv.DictReader(fp,delimiter = '\\t'):\n",
    "            try:\n",
    "                sent_id = record['id'].lower().strip()\n",
    "                paraphrase_data.append((preprocess_string(record['sentence1']), preprocess_string(record['sentence2']), int(float(record['is_duplicate'])),sent_id))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    print(f\"Loaded {len(paraphrase_data)} {split} examples from {paraphrase_filename}\")\n",
    "\n",
    "    similarity_data = []\n",
    "    with open(similarity_filename, 'r') as fp:\n",
    "        for record in csv.DictReader(fp,delimiter = '\\t'):\n",
    "            sent_id = record['id'].lower().strip()\n",
    "            similarity_data.append((preprocess_string(record['sentence1']), preprocess_string(record['sentence2']), float(record['similarity']),sent_id))\n",
    "\n",
    "    print(f\"Loaded {len(similarity_data)} {split} examples from {similarity_filename}\")\n",
    "    return sentiment_data, paraphrase_data, similarity_data, emotion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "args= {\n",
    "    'batch_size': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 train examples from ./test_data/test_sentiment.csv\n",
      "Loaded 30 train examples from ./test_data/test_emotion.csv\n",
      "Loaded 30 train examples from ./test_data/test_paraphase.csv\n",
      "Loaded 30 train examples from ./test_data/test_similarity.csv\n"
     ]
    }
   ],
   "source": [
    "files= { 'sst_file': './test_data/test_sentiment.csv', 'para_file': './test_data/test_paraphase.csv', 'sts_file': './test_data/test_similarity.csv', 'emt_file': './test_data/test_emotion.csv' }\n",
    "sst_test_data, para_test_data, sts_test_data, emt_test_data = load_multitask_data( files['sst_file'], files['para_file'], files['sts_file'], files['emt_file'])\n",
    "\n",
    "\n",
    "sst_test_data = SentenceClassificationDataset(sst_test_data)\n",
    "sst_test_dataloader = DataLoader(sst_test_data, shuffle=True, batch_size=args['batch_size'], collate_fn=sst_test_data.collate_fn)\n",
    "\n",
    "emt_test_data = SentenceClassificationDataset( emt_test_data)\n",
    "emt_test_dataloader = DataLoader( emt_test_data, shuffle=True, batch_size=args['batch_size'], collate_fn=emt_test_data.collate_fn)\n",
    "\n",
    "para_test_data = SentencePairDataset(para_test_data)\n",
    "para_test_dataloader = DataLoader(para_test_data, shuffle=True, batch_size=args['batch_size'],collate_fn=para_test_data.collate_fn)\n",
    "\n",
    "sts_test_data = SentencePairDataset(sts_test_data)\n",
    "sts_test_dataloader = DataLoader(sts_test_data, shuffle=True, batch_size=args['batch_size'],collate_fn=sts_test_data.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bert_MultiTask(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout_sentiment): ModuleList(\n",
       "    (0-2): 3 x Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (linear_sentiment): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=768, out_features=768, bias=True)\n",
       "    (2): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       "  (dropout_emotion): ModuleList(\n",
       "    (0-2): 3 x Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (linear_emotion): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=768, out_features=768, bias=True)\n",
       "    (2): Linear(in_features=768, out_features=14, bias=True)\n",
       "  )\n",
       "  (dropout_paraphrase): ModuleList(\n",
       "    (0-2): 3 x Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (linear_paraphrase): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=768, out_features=768, bias=True)\n",
       "    (2): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       "  (dropout_similarity): ModuleList(\n",
       "    (0-2): 3 x Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (linear_similarity): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=768, out_features=768, bias=True)\n",
       "    (2): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Bert_MultiTask(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Bert_MultiTask, self).__init__()\n",
    "        self.model = BertModel.from_pretrained(\"bert-base-uncased\", torch_dtype=torch.float16); self.model.to(\"cpu\")\n",
    "        self.tokenizer= BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        BERT_HIDDEN_SIZE = 768\n",
    "        \n",
    "        N_SENTIMENT_CLASSES = 5;    N_EMOTION_CLASSES= 14\n",
    "\n",
    "        # defining the linear layers for sentiment classification\n",
    "        self.dropout_sentiment = nn.ModuleList([nn.Dropout(config.hidden_dropout_prob) for _ in range(config.n_hidden_layers + 1)])\n",
    "        self.linear_sentiment = nn.ModuleList([nn.Linear(BERT_HIDDEN_SIZE, BERT_HIDDEN_SIZE, dtype=torch.float16) for _ in range(config.n_hidden_layers)] + [nn.Linear(BERT_HIDDEN_SIZE, N_SENTIMENT_CLASSES, dtype=torch.float16)])\n",
    "        self.last_linear_sentiment = None\n",
    "\n",
    "        # defining the layers for emotion detection\n",
    "        self.dropout_emotion = nn.ModuleList([nn.Dropout(config.hidden_dropout_prob) for _ in range(config.n_hidden_layers + 1)])\n",
    "        self.linear_emotion = nn.ModuleList([nn.Linear(BERT_HIDDEN_SIZE, BERT_HIDDEN_SIZE, dtype=torch.float16) for _ in range(config.n_hidden_layers)] + [nn.Linear(BERT_HIDDEN_SIZE, N_EMOTION_CLASSES, dtype=torch.float16)])\n",
    "        self.last_linear_emotion = None\n",
    "\n",
    "        # Add a linear layer for paraphrase detection\n",
    "        self.dropout_paraphrase = nn.ModuleList([nn.Dropout(config.hidden_dropout_prob) for _ in range(config.n_hidden_layers + 1)])\n",
    "        self.linear_paraphrase = nn.ModuleList([nn.Linear(BERT_HIDDEN_SIZE, BERT_HIDDEN_SIZE, dtype=torch.float16) for _ in range(config.n_hidden_layers)] + [nn.Linear(BERT_HIDDEN_SIZE, 1, dtype=torch.float16)])\n",
    "\n",
    "        # Add a linear layer for semantic textual similarity\n",
    "        self.dropout_similarity = nn.ModuleList([nn.Dropout(config.hidden_dropout_prob) for _ in range(config.n_hidden_layers + 1)])\n",
    "        self.linear_similarity = nn.ModuleList([nn.Linear(BERT_HIDDEN_SIZE, BERT_HIDDEN_SIZE,dtype=torch.float16) for _ in range(config.n_hidden_layers)] + [nn.Linear(BERT_HIDDEN_SIZE, 1,dtype=torch.float16)])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, task_id):\n",
    "        with torch.autocast(device_type='cpu', dtype=torch.float16):\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the [CLS] token embedding\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  \n",
    "        combined_embedding = cls_embedding\n",
    "        return combined_embedding\n",
    "    \n",
    "    def last_layers_sentiment(self, x):\n",
    "        for i in range(len(self.linear_sentiment) - 1):\n",
    "            x = self.dropout_sentiment[i](x)\n",
    "            x.to(torch.float16)\n",
    "            x = self.linear_sentiment[i](x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        x = self.dropout_sentiment[-1](x)\n",
    "        logits = self.linear_sentiment[-1](x)\n",
    "        return logits\n",
    "    \n",
    "    def predict_sentiment(self, input_ids, attention_mask):\n",
    "        x = self.forward(input_ids, attention_mask, task_id=0 )\n",
    "        x = self.last_layers_sentiment(x)\n",
    "        return x\n",
    "    \n",
    "    def last_layers_emotion(self, x):\n",
    "        for i in range(len(self.linear_emotion) - 1):\n",
    "            x = self.dropout_emotion[i](x)\n",
    "            x.to(torch.float16)\n",
    "            x = self.linear_emotion[i](x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        x = self.dropout_emotion[-1](x)\n",
    "        logits = self.linear_emotion[-1](x)\n",
    "        return logits\n",
    "    \n",
    "    def predict_emotion(self, input_ids, attention_mask):\n",
    "        x = self.forward(input_ids, attention_mask, task_id=3 )\n",
    "        x = self.last_layers_emotion(x)\n",
    "        return x\n",
    "\n",
    "    def get_similarity_paraphrase_embeddings(self, input_ids_1, attention_mask_1, input_ids_2, attention_mask_2, task_id):\n",
    "        # Get [SEP] token ids\n",
    "        sep_token_id = torch.tensor([self.tokenizer.sep_token_id], dtype=torch.long, device=input_ids_1.device)\n",
    "        batch_sep_token_id = sep_token_id.repeat(input_ids_1.shape[0], 1)\n",
    "\n",
    "        # Concatenate the two sentences in: sent1 [SEP] sent2 [SEP]\n",
    "        input_id = torch.cat((input_ids_1, batch_sep_token_id, input_ids_2, batch_sep_token_id), dim=1)\n",
    "        attention_mask = torch.cat((attention_mask_1, torch.ones_like(batch_sep_token_id), attention_mask_2, torch.ones_like(batch_sep_token_id)), dim=1)\n",
    "        x = self.forward(input_id, attention_mask, task_id=task_id)\n",
    "        return x\n",
    "\n",
    "    def last_layers_paraphrase(self, x):\n",
    "        for i in range(len(self.linear_paraphrase) - 1):\n",
    "            x = self.dropout_paraphrase[i](x)\n",
    "            x = self.linear_paraphrase[i](x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        x = self.dropout_paraphrase[-1](x)\n",
    "        logits = self.linear_paraphrase[-1](x)\n",
    "        return logits\n",
    "\n",
    "    def predict_paraphrase(self, input_ids_1, attention_mask_1, input_ids_2, attention_mask_2):\n",
    "        x = self.get_similarity_paraphrase_embeddings(input_ids_1, attention_mask_1, input_ids_2, attention_mask_2, task_id=1)\n",
    "        return self.last_layers_paraphrase(x)\n",
    "\n",
    "\n",
    "    def last_layers_similarity(self, x):\n",
    "        for i in range(len(self.linear_similarity) - 1):\n",
    "            x = self.dropout_similarity[i](x)\n",
    "            x = self.linear_similarity[i](x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        x = self.dropout_similarity[-1](x)\n",
    "        preds = self.linear_similarity[-1](x)\n",
    "        preds = torch.sigmoid(preds) * 4 + 1\n",
    "        return preds\n",
    "    \n",
    "    def predict_similarity(self,input_ids_1, attention_mask_1,input_ids_2, attention_mask_2):\n",
    "        x = self.get_similarity_paraphrase_embeddings(input_ids_1, attention_mask_1, input_ids_2, attention_mask_2, task_id=2)\n",
    "        return self.last_layers_similarity(x)\n",
    "    \n",
    "device= torch.device(\"cpu\")\n",
    "model= torch.load('multimodel.pt', weights_only=False).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 15/15 [04:29<00:00, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score has come out to be: 0.06666666666666667\n",
      "Accuracy for the test set: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_true = []; y_pred = []; sents = []\n",
    "    sent_ids = []\n",
    "    for step, batch in enumerate(tqdm( sst_test_dataloader, desc=f'eval')):\n",
    "        b_ids, b_mask, b_labels, b_sents, b_sent_ids = batch['token_ids'],batch['attention_mask'],  batch['labels'], batch['sents'], batch['sent_ids']\n",
    "        b_ids = b_ids.to(device);   b_mask = b_mask.to(device)  \n",
    "        logits = model.predict_sentiment(b_ids, b_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=1).flatten()\n",
    "        b_labels = b_labels.flatten()\n",
    "\n",
    "        y_true.extend(b_labels)\n",
    "        y_pred.extend(preds)\n",
    "        sents.extend(b_sents)\n",
    "        sent_ids.extend(b_sent_ids) \n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"F1 Score has come out to be: {f1}\\nAccuracy for the test set: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paraphase Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 15/15 [02:39<00:00, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphase Accuracy has come  to be: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    para_y_pred = []; para_sent_ids = []; para_y_true= []\n",
    "    for step, batch in enumerate(tqdm( para_test_dataloader, desc=f'eval')):\n",
    "        (b_ids1, b_mask1, b_ids2, b_mask2, b_labels, b_sent_ids) = (batch['token_ids_1'], batch['attention_mask_1'], batch['token_ids_2'], batch['attention_mask_2'], batch['labels'], batch['sent_ids'])\n",
    "        b_ids1 = b_ids1.to(device)\n",
    "        b_mask1 = b_mask1.to(device)\n",
    "        b_ids2 = b_ids2.to(device)\n",
    "        b_mask2 = b_mask2.to(device)\n",
    "        logits = model.predict_paraphrase(b_ids1, b_mask1, b_ids2, b_mask2)\n",
    "        y_hat = logits.sigmoid().round().flatten().cpu().numpy()\n",
    "        \n",
    "        b_labels = b_labels.flatten().cpu().numpy()\n",
    "        \n",
    "        para_y_pred.extend(y_hat)\n",
    "        para_y_true.extend(b_labels)\n",
    "        para_sent_ids.extend(b_sent_ids)\n",
    "\n",
    "paraphrase_accuracy = np.mean(np.array(para_y_pred) == np.array(para_y_true))\n",
    "print(f\"Paraphase Accuracy has come  to be: {paraphrase_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 15/15 [01:20<00:00,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Correlation Coefficient from the pearson matrix: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sts_y_true = [];    sts_y_pred = [];    sts_sent_ids = []\n",
    "    for step, batch in enumerate(tqdm(sts_test_dataloader, desc=f'eval')):\n",
    "        (b_ids1, b_mask1,b_ids2, b_mask2, b_labels, b_sent_ids) = (batch['token_ids_1'], batch['attention_mask_1'], batch['token_ids_2'], batch['attention_mask_2'], batch['labels'], batch['sent_ids'])\n",
    "        b_ids1 = b_ids1.to(device)\n",
    "        b_mask1 = b_mask1.to(device)\n",
    "        b_ids2 = b_ids2.to(device)\n",
    "        b_mask2 = b_mask2.to(device)\n",
    "        \n",
    "        logits = model.predict_similarity(b_ids1, b_mask1, b_ids2, b_mask2)\n",
    "        y_hat = logits.flatten().cpu().numpy()\n",
    "        b_labels = b_labels.flatten().cpu().numpy()\n",
    "        \n",
    "        sts_y_pred.extend(y_hat);   sts_y_true.extend(b_labels);    sts_sent_ids.extend(b_sent_ids)\n",
    "    \n",
    "# Calculating pearson matrix\n",
    "pearson_mat = np.corrcoef(sts_y_pred,sts_y_true)\n",
    "sts_corr = pearson_mat[1][0]\n",
    "print(f\"The Correlation Coefficient from the pearson matrix: {sts_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 15/15 [01:34<00:00,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score has come out to be: 0.01075268817204301\n",
      "Accuracy for the test set: 0.03333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    emt_y_true = []\n",
    "    emt_y_pred = []\n",
    "    emt_sent_ids = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(emt_test_dataloader, desc=f'eval')):\n",
    "        b_ids, b_mask, b_labels, b_sent_ids = batch['token_ids'], batch['attention_mask'], batch['labels'], batch['sent_ids']\n",
    "        b_ids = b_ids.to(device)\n",
    "        b_mask = b_mask.to(device)\n",
    "\n",
    "        logits = model.predict_emotion(b_ids, b_mask)\n",
    "        y_hat = logits.argmax(dim=-1).flatten().cpu().numpy()\n",
    "        b_labels = b_labels.flatten().cpu().numpy()\n",
    "\n",
    "        emt_y_pred.extend(y_hat);   emt_y_true.extend(b_labels);    emt_sent_ids.extend(b_sent_ids)\n",
    "\n",
    "f1 = f1_score(emt_y_true, emt_y_pred, average='macro')\n",
    "acc = accuracy_score(emt_y_true, emt_y_pred)\n",
    "print(f\"F1 Score has come out to be: {f1}\\nAccuracy for the test set: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hp3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
